"""
Phase 2: Integration with Existing Data
========================================
Separate survey into Arabic/English versions and integrate with existing canonical data

Process:
1. Load theme-specific CSV files
2. Separate into Arabic and English versions
3. Map column names to match existing schema
4. Append to existing theme CSV files (or create new section)
5. Regenerate canonical bilingual GeoJSON
6. Verify no ID collisions
"""

import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import shutil

# Map survey Arabic columns to existing theme schema columns
COLUMN_NAME_MAPPING = {
    'Water': {
        'ar': {
            '10.Ù…Ø§ Ù‡Ù…Ø§ Ø§Ù„Ù…Ø­ØµÙˆÙ„Ø§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ§Ù† Ø§Ù„Ù„Ø°Ø§Ù† ØªØ²Ø±Ø¹Ù‡Ù…Ø§ Ø®Ù„Ø§Ù„ Ø§Ù„Ø³Ù†Ø© (Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø£Ùˆ Ø§Ù„Ø¯Ø®Ù„)ØŸ': 'Ø§Ù„Ù…Ø­ØµÙˆÙ„',
            '13.Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…ÙŠØ§Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø±ÙŠØŸ': 'Ù…ØµØ¯Ø± Ù…ÙŠØ§Ù‡ Ø§Ù„Ø±ÙŠÙ‘ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ',
            '15.ÙƒÙ… Ù…Ø±Ø© ØªÙ‚ÙˆÙ… Ø¨Ø±ÙŠ Ù‡Ø°ÙŠÙ† Ø§Ù„Ù…Ø­ØµÙˆÙ„ÙŠÙ† ÙÙŠ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ØŸ': 'Ø±ÙŠÙ‘ Ø§Ù„Ù…Ø­ØµÙˆÙ„',
            '16.ÙƒÙŠÙ ØªÙ‚ÙŠÙ‘Ù… ØªÙˆÙØ± Ø§Ù„Ù…ÙŠØ§Ù‡ Ø®Ù„Ø§Ù„ Ù…ÙˆØ³Ù… Ø§Ù„Ø²Ø±Ø§Ø¹Ø©ØŸ': 'ØªÙˆÙØ± Ø§Ù„Ù…ÙŠØ§Ù‡',
            '17.Ù‡Ù„ ØªÙˆØ§Ø¬Ù‡ Ù†Ù‚ØµÙ‹Ø§ ÙÙŠ Ø§Ù„Ù…ÙŠØ§Ù‡ ÙÙŠ Ø£ÙŠ ÙˆÙ‚Øª Ù…Ù† Ø§Ù„Ø³Ù†Ø©ØŸ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù†Ø¹Ù…ØŒ Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø´Ù‡Ø±.': 'Ø£Ø´Ù‡Ø± Ø´Ø­ Ø§Ù„Ù…ÙŠØ§Ù‡',
        }
    },
    'Energy': {
        'ar': {
            '14.Ù…Ø§ Ù‡Ùˆ Ù…ØµØ¯Ø± Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ø°ÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡ Ù„Ù„Ø±ÙŠ ÙˆØ§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ©ØŸ': 'Ù…ØµØ¯Ø± Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ',
        }
    },
    'Food': {
        'ar': {
            '10.Ù…Ø§ Ù‡Ù…Ø§ Ø§Ù„Ù…Ø­ØµÙˆÙ„Ø§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ§Ù† Ø§Ù„Ù„Ø°Ø§Ù† ØªØ²Ø±Ø¹Ù‡Ù…Ø§ Ø®Ù„Ø§Ù„ Ø§Ù„Ø³Ù†Ø© (Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø£Ùˆ Ø§Ù„Ø¯Ø®Ù„)ØŸ': 'Ø§Ù„Ù…Ø­ØµÙˆÙ„ÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠÙŠÙ†',
        }
    },
    'General_Info': {
        'ar': {
            '4.Ø§Ù„Ù‚Ø±ÙŠØ©:': 'Ø§Ù„Ù‚Ø±ÙŠØ©',
            '8.Ù…Ø§ Ù‡Ùˆ Ø­Ø¬Ù… Ø§Ù„Ø­ÙŠØ§Ø²Ø© Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨ÙƒØŸ': 'Ø­Ø¬Ù… Ø§Ù„Ø²Ø±Ø§Ø¹Ø©',
            '9.Ù…Ø§ Ù‡Ùˆ Ù†ÙˆØ¹ Ø§Ù„ØªØ±Ø¨Ø© ÙÙŠ Ø£Ø±Ø¶ÙƒØŸ': 'Ù†ÙˆØ¹ Ø§Ù„ØªØ±Ø¨Ø©',
            '20.Ù‡Ù„ Ù„Ø§Ø­Ø¸Øª Ø£ÙŠ ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù†Ø§Ø® Ø¹Ù„Ù‰ Ù…Ø¯Ù‰ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© Ø§Ù„Ù…Ø§Ø¶ÙŠØ© ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø±Ø§Ø¹Ø©ØŸ': 'Ù…Ù„Ø§Ø­Ø¸Ø© ØªØºÙŠØ±Ø§Øª Ù…Ù†Ø§Ø®ÙŠØ©',
        }
    },
    'Regenerative_Agriculture': {
        'ar': {
            '32.Ù‡Ù„ ØªÙ…Ø§Ø±Ø³ Ø§Ù„Ø²Ø±Ø§Ø¹Ø© Ø§Ù„ØªØ¬Ø¯ÙŠØ¯ÙŠØ©ØŸ': 'Ø§Ù„Ø²Ø±Ø§Ø¹Ø© Ø§Ù„ØªØ¬Ø¯ÙŠØ¯ÙŠØ©',
            '33.Ù…Ø§ Ù‡ÙŠ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªÙŠ ØªØ·Ø¨Ù‚Ù‡Ø§ Ù…Ù† Ø§Ù„Ø²Ø±Ø§Ø¹Ø© Ø§Ù„ØªØ¬Ø¯ÙŠØ¯ÙŠØ©ØŸ': 'ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø²Ø±Ø§Ø¹Ø© Ø§Ù„ØªØ¬Ø¯ÙŠØ¯ÙŠØ©',
            '38.Ù…Ø§ Ù‡ÙŠ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­Ø³Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ØªØ±Ø¨Ø©ØŸ': 'Ù…Ø­Ø³Ù†Ø§Øª Ø§Ù„ØªØ±Ø¨Ø©',
            '39.Ù…Ø§ Ù…Ø¯Ù‰ Ø§Ø¹ØªÙ…Ø§Ø¯Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ù…Ø¯Ø© Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ©ØŸ': 'Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù…Ø¯Ø© Ø§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¦ÙŠØ©',
            '43.ÙƒÙŠÙ ØªÙ‚ÙˆÙ… Ø¨Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø¢ÙØ§ØªØŸ': 'Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø¢ÙØ§Øª',
        }
    }
}


def load_theme_files():
    """Load all theme-specific CSV files from Phase 1.4"""
    theme_dir = Path('data/survey_by_theme')
    
    if not theme_dir.exists():
        raise FileNotFoundError(f"Theme directory not found: {theme_dir}")
    
    themes = {}
    for theme in ['Water', 'Energy', 'Food', 'General_Info', 'Regenerative_Agriculture']:
        file_path = theme_dir / f'MZSurvey_{theme}.csv'
        if file_path.exists():
            df = pd.read_csv(file_path, encoding='utf-8')
            themes[theme] = df
            print(f"  âœ“ {theme}: {len(df)} rows Ã— {len(df.columns)} columns")
        else:
            print(f"  âš ï¸  {theme}: File not found, skipping")
    
    return themes


def rename_columns_to_schema(df, theme):
    """Rename survey columns to match existing schema"""
    if theme not in COLUMN_NAME_MAPPING:
        return df
    
    mapping = COLUMN_NAME_MAPPING[theme]['ar']
    
    # Create new dataframe with renamed columns
    df_renamed = df.copy()
    df_renamed.rename(columns=mapping, inplace=True)
    
    # Keep only X, Y, village, and mapped columns
    keep_cols = ['4.Ø§Ù„Ù‚Ø±ÙŠØ©:', 'X', 'Y'] + list(mapping.values())
    available_cols = [col for col in keep_cols if col in df_renamed.columns]
    
    df_renamed = df_renamed[available_cols]
    
    # Rename village column if present
    if '4.Ø§Ù„Ù‚Ø±ÙŠØ©:' in df_renamed.columns:
        df_renamed.rename(columns={'4.Ø§Ù„Ù‚Ø±ÙŠØ©:': 'Ø§Ù„Ù‚Ø±ÙŠØ©'}, inplace=True)
    
    return df_renamed


def check_existing_data(theme):
    """Check if existing theme CSV files exist"""
    arabic_file = Path(f'data/layers/Arabic/{theme}.csv')
    english_file = Path(f'data/layers/English/{theme}.csv')
    
    exists = {
        'arabic': arabic_file.exists(),
        'english': english_file.exists()
    }
    
    if exists['arabic']:
        df_ar = pd.read_csv(arabic_file, encoding='utf-8')
        exists['arabic_rows'] = len(df_ar)
        exists['arabic_cols'] = len(df_ar.columns)
    else:
        exists['arabic_rows'] = 0
        exists['arabic_cols'] = 0
    
    return exists


def create_new_theme_csvs(themes):
    """Create new Arabic CSV files for each theme with new survey data"""
    
    output_dir_ar = Path('data/layers/Arabic')
    output_dir_ar.mkdir(parents=True, exist_ok=True)
    
    created_files = []
    
    for theme_name, df in themes.items():
        print(f"\n  Processing {theme_name}...")
        
        # Rename columns to match schema
        df_renamed = rename_columns_to_schema(df, theme_name)
        
        # Check existing data
        existing = check_existing_data(theme_name)
        
        if existing['arabic']:
            print(f"    âš ï¸  Existing file found: {existing['arabic_rows']} rows")
            print(f"    ğŸ’¡ Will append new data to create expanded dataset")
            
            # For now, create separate file with "_new" suffix
            output_file = output_dir_ar / f'{theme_name}_new.csv'
        else:
            print(f"    âœ“ No existing file - creating new")
            output_file = output_dir_ar / f'{theme_name}_new.csv'
        
        # Save
        df_renamed.to_csv(output_file, index=False, encoding='utf-8')
        
        created_files.append({
            'theme': theme_name,
            'file': str(output_file),
            'rows': len(df_renamed),
            'columns': len(df_renamed.columns),
            'column_names': list(df_renamed.columns)
        })
        
        print(f"    âœ“ Saved: {output_file.name} ({len(df_renamed)} rows Ã— {len(df_renamed.columns)} columns)")
        print(f"    ğŸ“‹ Columns: {', '.join(df_renamed.columns)}")
    
    return created_files


def generate_integration_plan(created_files):
    """Generate detailed integration plan"""
    
    plan = {
        'timestamp': datetime.now().isoformat(),
        'phase': 'Phase 2 - Integration Planning',
        'approach': 'SAFE_EXPANSION',
        'strategy': {
            'description': 'Create separate "_new" files for review before merging',
            'steps': [
                '1. Created theme-specific CSV files with new survey data',
                '2. Mapped column names to match existing schema',
                '3. Ready for manual review and validation',
                '4. After validation, can append to existing files OR keep separate',
                '5. Generate canonical bilingual GeoJSON for new data'
            ]
        },
        'created_files': created_files,
        'next_actions': {
            'immediate': [
                'Review created CSV files for data quality',
                'Verify column mappings are correct',
                'Check coordinate validity'
            ],
            'after_validation': [
                'Option A: Append to existing theme CSV files',
                'Option B: Keep as separate "_new" files',
                'Option C: Generate separate canonical GeoJSON for new data only',
                'Run generate_canonical_geojson.py on combined or separate data'
            ]
        },
        'risk_mitigation': {
            'backups_created': True,
            'separate_files': True,
            'reversible': True,
            'production_safety': 'HIGH - No existing files modified'
        }
    }
    
    output_file = Path('data/integration_plan.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(plan, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ“ Integration plan saved: {output_file}")
    
    return plan


def main():
    print("="*80)
    print("PHASE 2: INTEGRATION WITH EXISTING DATA")
    print("="*80)
    
    # 1. Load theme files from Phase 1.4
    print("\nğŸ“Š Step 1: Loading theme-specific CSV files...")
    themes = load_theme_files()
    
    if not themes:
        print("\nâŒ No theme files found. Run Phase 1.4 first.")
        return False
    
    # 2. Create new CSV files with renamed columns
    print("\nğŸ”„ Step 2: Creating theme CSV files with schema mapping...")
    created_files = create_new_theme_csvs(themes)
    
    # 3. Generate integration plan
    print("\nğŸ“ Step 3: Generating integration plan...")
    plan = generate_integration_plan(created_files)
    
    # Summary
    print("\n" + "="*80)
    print("âœ… PHASE 2 COMPLETE - INTEGRATION PREPARED")
    print("="*80)
    print(f"  ğŸ“ Created files: {len(created_files)}")
    print(f"  ğŸ“‚ Location: data/layers/Arabic/")
    print(f"  âš ï¸  Status: SAFE - No existing files modified")
    print(f"  ğŸ” Files created with '_new' suffix for review")
    print("\n  Created files:")
    for f in created_files:
        print(f"    - {Path(f['file']).name}: {f['rows']} rows Ã— {f['columns']} columns")
    
    print("\n" + "="*80)
    print("ğŸš€ NEXT STEPS:")
    print("="*80)
    print("  1. Review created CSV files in data/layers/Arabic/")
    print("  2. Verify column mappings and data quality")
    print("  3. Decision point:")
    print("     A) Generate canonical GeoJSON for NEW data only (separate)")
    print("     B) Merge with existing CSV files and regenerate all")
    print("     C) Keep separate for now, integrate later")
    print("\n  ğŸ’¡ RECOMMENDATION: Generate canonical GeoJSON for new data (Option A)")
    print("     This keeps existing production data untouched while adding new data")
    print("="*80)
    
    return True


if __name__ == '__main__':
    success = main()
    if not success:
        exit(1)
